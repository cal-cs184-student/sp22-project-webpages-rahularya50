<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../pandoc.css" type="text/css" />
</head>
<body>
<h1 id="project-1">Project 1</h1>
<p>In this project, I filled in code to complete the implementation of a SVG renderer. Specifically, I implemented logic to (semi-efficiently) identify which pixels lie inside a triangle based on the location of its vertices. I implemented supersampling-based anti-aliasing to reduce &quot;jaggies&quot; in the rendering. For triangles, I also implemented color and texture interpolation based on barycentric coordinates. The textures were sampled using various forms of interpolation, using mipmaps to efficiently remove high-frequency artifacts as appropriate.</p>
<h2 id="task-1">Task 1</h2>
<p>Each triangle is defined by three points <span class="math inline">(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span> for <span class="math inline">0 ≤ <em>i</em> &lt; 3</span>. We first compute the bounding box of the triangle, bounded by the minimum and maximum x and y coordinates of these three points. Then, we loop over each test point <span class="math inline">(<em>x</em>, <em>y</em>)</span> within this bounding box to check if it lies inside the triangle.</p>
<p>To do so, we make the following observation. Consider a vector representing the direction of a line passing through the origin. Rotate it 90 degrees counterclockwise. Then project a test point onto this vector using dot products. The sign of this projection is positive if the test point is to the &quot;left&quot; of the original line (facing along the direction vector), zero if it lies on the line, and negative if it lies to the &quot;right&quot;. By translating all coordinates, we can make a similar determination for the position of a point with respect to a line not passing through the origin, so long as we know its direction vector and at least one point on the line.</p>
<p>Now, note that the triangle's vertices are ordered so they are oriented either &quot;clockwise&quot; or &quot;counter-clockwise&quot;. If clockwise, then a point lies inside the triangle iff it is not to the left of any line between two consecutive vertices. If counter-clockwise, then a point lies inside the triangle so long as it is not to the right of any line between consecutive vertices. So we can use the above sign-of-the-dot-product test to check if a point lies inside the triangle in either orientation. If so, we color it in, and otherwise we leave it blank.</p>
<p>Mathematically, the test looks like this (in pseudo-code):</p>
<pre><code>// let (x, y) be our test point
// let pts[i] = (xi, yi), where pts[0] == pts[3]
cw = true;
ccw = true;
for i in 0..3:
    // the line goes from pts[i] to pts[i+1]
    // treat pts[i+1] as the offset, to translate our line through the origin
    // let (dx, dy) be the direction vector of the line
    dx = pts[i+1][0] - pts[i][0];
    dy = pts[i+1][1] - pts[i][1];

    // we are taking the inner product of (-dy, dx) with ((x, y) - offset)
    auto l = -(x - pts[i+1][0]) * dy + (y - pts[i+1][1]) * dx;

    // if we lie to the left or the right of a line,
    // we rule out the clockwise/counter-clockwise cases, respectively
    if (l &gt; 0) {
        cw = false;
    }
    if (l &lt; 0) {
        ccw = false;
    }
}

// if we are consistent with one orientation, then we are inside the triangle!
inside_triangle = cw || ccw;</code></pre>
<p>My algorithm literally just checks every sample within the bounding box, so it is obviously no worse than such an approach.</p>
<p>A rendering of <code>basic/test4.svg</code> follows: <img src="q1.png" alt="q1.png" /></p>
<p>The inspector is zoomed in on the rightmost coerner of the red triangle. We see jaggies due to the lack of anti-aliasing, as the triangle thins to a point.</p>
<h2 id="task-2">Task 2</h2>
<p>In supersampling, we increase the size of the <code>sample_buffer</code> to <code>width * height * sample_rate</code>. We index into it as <code>sample_buffer[y * width * sample_scale + x]</code>, where <code>sample_scale * sample_scale = sample_rate</code>, and <code>x</code> and <code>y</code> are the supersampled coordinates such that <code>0 &lt;= x &lt; sample_scale * width</code>, and <code>0 &lt;= y &lt; sample_scale * height</code>.</p>
<p>The <code>fill_pixel(x0, y0)</code> function is modified to fill in all points <code>(x, y)</code> where <code>x0 * sample_scale &lt;= x &lt; (x0 + 1) * sample_scale</code> and analogously for <code>y</code>, so we are essentially filling in a small &quot;box&quot; in the buffer. So for points and lines, which use this function, supersampling has no effect.</p>
<p>However, we do modify the <code>rasterize_triangle</code> function to test each sample in the aforementioned &quot;box&quot; for membership in the triangle separately. This is useful, since then if the border of the triangle passes &quot;partially&quot; through the box associated with an actual output pixel, we end up coloring in that output box &quot;partly&quot;, making the borders &quot;fuzzier&quot; and reducing the effects of jaggies. The fuzziness comes from the color averaging process as we write to the framebuffer.</p>
<p>Finally, we modify the <code>resolve_to_framebuffer</code> function to average the color of each point in the &quot;box&quot; corresponding to an actual output point <code>(x, y)</code>, before writing to the <code>rgb_framebuffer_target</code>.</p>
<p>Below, we show how <code>basic/test4.svg</code> is rendered with sample rates 1, 4, 9, and 16 (left-to-right, then top-to-bottom):</p>
<p><img src="q2a.png" alt="q2a.png" style="width:49.0%" /> <img src="q2b.png" alt="q2b.png" style="width:49.0%" /> <img src="q2c.png" alt="q2c.png" style="width:49.0%" /> <img src="q2d.png" alt="q2d.png" style="width:49.0%" /></p>
<p>Observe how the sharp corner of the triangle begins to &quot;blur&quot; into the background. This is because we can now shade pixels based on the &quot;fraction&quot; that they are covered by the triangle (estimated using supersampling), rather than shading them either entirely, or not at all, depending on whether the triangle covers the center point of the pixel. The greater the sample rate, the more accurate this estimate becomes, and so the &quot;smoother&quot; the corner becomes&quot;</p>
<h2 id="task-3">Task 3</h2>
<p>Cubeman is <a href="https://en.wikipedia.org/wiki/Dab_(dance)">dabbing</a>. <img src="q3.png" alt="q3.png" /></p>
<p>I rotated the arms and legs after their translation, and changed the color of the arms to make them more visible. I also scaled the head down in the y-direction and translated it vertically slightly.</p>
<h2 id="task-4">Task 4</h2>
<p>Imagine a triangle with coordinates <span class="math inline">(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span> for <span class="math inline">0 ≤ <em>i</em> &lt; 3</span>. Consider some other point <span class="math inline">(<em>x</em>, <em>y</em>)</span>. We wish to find coefficients <span class="math inline"><em>α</em>, <em>β</em>, <em>γ</em></span> such that <span class="math inline"><em>x</em> = <em>α</em><em>x</em><sub>0</sub> + <em>β</em><em>x</em><sub>1</sub> + <em>γ</em><em>x</em><sub>2</sub></span> and <span class="math inline"><em>y</em> = <em>α</em><em>y</em><sub>0</sub> + <em>β</em><em>y</em><sub>1</sub> + <em>γ</em><em>y</em><sub>2</sub></span>. Since there are three unknowns and only two constraints, this system is underdetermined. So we add the constraint <span class="math inline"><em>α</em> + <em>β</em> + <em>γ</em> = 1</span> to give us a unique solution.</p>
<p>Notice that <span class="math inline"><em>α</em> = 1</span> and <span class="math inline"><em>β</em>, <em>γ</em> = 0</span> at <span class="math inline">(<em>x</em>, <em>y</em>)=(<em>x</em><sub>0</sub>, <em>y</em><sub>0</sub>)</span>, and similarly for the other two vertices. Moreover, we can show that <span class="math inline"><em>α</em>, <em>β</em>, <em>γ</em> ≥ 0</span> exactly for points inside the triangle. So we can interpret these coefficients as &quot;weighting&quot; the three vertices, to give us a point somewhere inside their triangle. This gives us barycentric coordinates.</p>
<p><img src="q4a.png" alt="q4a.png" /> The above illustration shows how barycentric coordinates are used to weight the colors from each vertex of the triangle in order to shade its interior. The vertices are colored red, blue, and green, and we use the barycentric coordinates of each interior point to weight the color of the vertices and smoothly interpolate between them.</p>
<p>A rendering of <code>basic/test7.svg</code> follows: <img src="q4b.png" alt="q4b.png" /></p>
<h2 id="task-5">Task 5</h2>
<p>When sampling from a texture, we use barycentric coordinates to map each point <span class="math inline">(<em>x</em>, <em>y</em>)</span> within a textured triangle to coordinates <span class="math inline">(<em>u</em>, <em>v</em>)</span> on a texture image, scaled such that <code>0 &lt;= u &lt; width</code> and <code>0 &lt;= v &lt; height</code>. These may be non-integral values, so they do not correspond exactly to pixels in the texture.</p>
<p>The <code>P_NEAREST</code> sampling technique rounds <code>u</code> and <code>v</code> to integers, so they correspond to a single pixel from the source texture, which we use as our sampled color. The <code>P_LINEAR</code> technique interpolates between the four surrounding pixels closest to <span class="math inline">(<em>u</em>, <em>v</em>)</span>. Specifically, let <span class="math inline">(<em>u</em><sub>0</sub>, <em>v</em><sub>0</sub>)</span> represent the rounded version of <span class="math inline">(<em>u</em>, <em>v</em>)</span>, rounding down to the nearest integer. Then the surrounding pixels used for interpolation are located at <span class="math inline">(<em>u</em><sub>0</sub>, <em>v</em><sub>0</sub>),(<em>u</em><sub>0</sub> + 1, <em>v</em><sub>0</sub>),(<em>u</em><sub>0</sub>, <em>v</em><sub>0</sub> + 1),(<em>u</em><sub>0</sub> + 1, <em>v</em><sub>0</sub> + 1)</span>. Bilinear interpolation first defines the constants <span class="math inline"><em>s</em> = <em>u</em> − <em>u</em><sub>0</sub></span> and <span class="math inline"><em>t</em> = <em>v</em> − <em>v</em><sub>0</sub></span>. Then, the interpolated color becomes</p>
<pre><code>color = (
    (1 - s) * (1 - t) * texture[u0, v0]
    + s * (1 - t) * texture[u0 + 1, v0]
    + (1 - s) * t * texture[u0, v0 + 1]
    + s * t * texture[u0 + 1, v0 + 1]
)</code></pre>
<p>So what we are doing here is weighting each of the four surrounding grid points quadratically based on the product of the horizonal and vertical distances between them and the sample point.</p>
<p>We now compare the nearest and bilinear sampling methods (left and right respectively) on a reference image using both 1x and 16x supersampling rates (top and bottom respectively):</p>
<p><img src="q5a.png" alt="q5a.png" style="width:49.0%" /> <img src="q5c.png" alt="q5c.png" style="width:49.0%" /> <img src="q5b.png" alt="q5b.png" style="width:49.0%" /> <img src="q5d.png" alt="q5d.png" style="width:49.0%" /></p>
<h2 id="part-6">Part 6</h2>
<p>To prevent aliasing effects, we woud like to sample from a texture with all frequencies higher than the sampling frequency removed. To do this, we prepare &quot;mipmaps&quot;, versions of the texture at progressively lower resolutions (by blurring adjacent pixels together). For each sample, we draw our color from the appropriate mipmap level, and avoid aliasing artifacts.</p>
<p>In <code>L_NEAREST</code> mode, we choose the mipmap level whose maximum frequency is nearest to our sampling frequency, and sample our pixel from it. In <code>L_LINEAR</code> mode, we sample from mipmap levels above and below the sampling frequency, then take a weighted average of them to produce the final output.</p>
<p>To determine our sampling frequency, we compute the texture sample points <code>(u, v)</code> for our test point <code>(x, y)</code>, as well as for <code>(x + 1, y)</code> and <code>(x, y + 1)</code>, then look at the differences in the texture sample points. We take the maximum length of the two texture position offset vectors to determine the lowest sample frequency, and then choose the mipmap whose resolution is closest to that.</p>
<p>Level sampling has the lowest performance overhead, since in <code>L_NEAREST</code> mode it just affects which mipmap we choose to use as a source for our sample. Even in <code>L_LINEAR</code> mode, we only need to make two samples, from the mipmaps above and below our target frequency, and then weight them together with a single lerp. However, it requires additional memory to store all the mipmaps to be used for sampling</p>
<p>Pixel sampling has a higher computation overhead, since we need to sample from four pixels and then perform three lerps to weight them together. But it does not require any additional memory to store textures / buffer output. It also provides better anti-aliasing / blur when our sampling frequency is higher than the source resolution of the texture, since the pixel boundaries are blurred together (as shown above).</p>
<p>Finally, supersampling has the greatest antialiasing power, but has the highest memory and runtime overhead. This is because we need to repeat all our computation once for each subsampled pixel, as well as store an output buffer <code>sample_rate</code> times larger than the actual frame buffer, so there is both a runtime and memory penalty. The advantage is that we get anti-aliasing not just for textures, but also for the edges of polygons.</p>
<p>We compare <code>L_ZERO</code> and <code>L_NEAREST</code> level sampling (top vs bottom) as well as <code>P_NEAREST</code> and <code>P_LINEAR</code> pixel sampling (left vs right) in the below grid.</p>
<p><img src="q6a.png" alt="q6a.png" style="width:49.0%" /> <img src="q6c.png" alt="q6c.png" style="width:49.0%" /> <img src="q6b.png" alt="q6b.png" style="width:49.0%" /> <img src="q6d.png" alt="q6d.png" style="width:49.0%" /></p>
<p>We see that with <code>L_NEAREST</code> level sampling, there is a discontinuity as we switch mipmap levels, where the &quot;blurriness&quot; of the image increases between triangles. We also see that with <code>P_LINEAR</code>, the image is also generally more &quot;blurry&quot; and individual pixels in the backing texture are less visible, since they are interpolated together.</p>
<p>Website link: <a href="https://cal-cs184-student.github.io/sp22-project-webpages-rahularya50/proj1/" class="uri">https://cal-cs184-student.github.io/sp22-project-webpages-rahularya50/proj1/</a>.</p>
</body>
</html>
